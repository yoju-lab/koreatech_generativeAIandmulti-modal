{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507fb2c8-6bf1-400a-9f24-0da07f23ae14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.4.1+cu124\n",
      "torchvision: 0.19.1+cu124\n",
      "CUDA available?: True\n",
      "GPU: NVIDIA A40\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"CUDA available?:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5186c39c-c349-4d16-854c-609f4c406b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 0. (ÌïÑÏöî Ïãú) Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò\n",
    "!pip install transformers>=4.40.0 pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565daa63-fd36-4b47-bfef-6432fd99c08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏûÑÌè¨Ìä∏\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b280be04-02eb-45f4-a976-5e36fb5d81a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 2. ÎîîÎ∞îÏù¥Ïä§ ÏÑ§Ï†ï\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83cb3b93-6111-44ad-89aa-3fb5b513a168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520c9f85bb954bfb86c17bf6d04f9dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a24f4f6a4f4ffdbaa0ff99382d674c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e195bfcbb6254fc8810dd15c0dd749d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67b83e97ee04d8f8b6083cc64372bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328808dd260e4ef8b666bdcbe837dce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22effc437914904beeb66304abbae85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05234ac34364e419e792ee95e8c29b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Î™®Îç∏Í≥º ÌîÑÎ°úÏÑ∏ÏÑú Î°úÎìú\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "model_name = \"Salesforce/blip-image-captioning-base\"\n",
    "\n",
    "# ‚ë† Îπ†Î•∏ ÌîÑÎ°úÏÑ∏ÏÑú ÏÇ¨Ïö©\n",
    "processor = BlipProcessor.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# ‚ë° Safetensors Ìè¨Îß∑ Í∞ïÏ†ú Î°úÎìú\n",
    "model = BlipForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    use_safetensors=True   # ‚ú® Ïù¥ ÏòµÏÖòÏùÑ Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a21b225a-310e-4a2d-b82a-e704facf08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Ïù¥ÎØ∏ÏßÄ Î∂àÎü¨Ïò§Í∏∞ Î∞è Ï†ÑÏ≤òÎ¶¨\n",
    "image_path = \"Golden-Retriever.jpg\"  # Î≥∏Ïù∏ ÌôòÍ≤ΩÏóê ÎßûÍ≤å Í≤ΩÎ°ú ÏàòÏ†ï\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbbf9c32-1b7a-4404-b61c-aa4a11381faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Ï∫°ÏÖò ÏÉùÏÑ±\n",
    "with torch.no_grad():\n",
    "    out_ids = model.generate(\n",
    "        pixel_values=inputs.pixel_values,\n",
    "        max_length=64,       # ÏÉùÏÑ±Ìï† ÏµúÎåÄ ÌÜ†ÌÅ∞ Í∏∏Ïù¥\n",
    "        num_beams=5,         # Îπî ÏÑúÏπò Ìè≠\n",
    "        early_stopping=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c69c2ee-0ae2-4b69-9225-d70b725681d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Generated Caption: a dog sitting on a log in a field\n"
     ]
    }
   ],
   "source": [
    "# 6. Í≤∞Í≥º ÎîîÏΩîÎî© Î∞è Ï∂úÎ†•\n",
    "caption = processor.decode(out_ids[0], skip_special_tokens=True)\n",
    "print(\"üîπ Generated Caption:\", caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce70cd-e8bf-488c-9479-2acd7f2ff674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da06d37-bf6c-48e7-a125-c09a46e9846d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
