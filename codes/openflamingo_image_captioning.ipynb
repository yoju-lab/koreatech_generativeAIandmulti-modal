{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f08bd2d",
   "metadata": {},
   "source": [
    "\n",
    "# 🚀 OpenFlamingo 이미지 설명 생성 실습\n",
    "\n",
    "이 노트북은 **OpenFlamingo** 모델을 사용하여 이미지를 설명하는 멀티모달(Multimodal) AI 예제입니다.\n",
    "\n",
    "**환경**: RunPod A40 GPU, PyTorch 2.0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c608d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision==0.15.2 in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
      "Collecting transformers==4.30.0\n",
      "  Downloading transformers-4.30.0-py3-none-any.whl.metadata (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting open-flamingo\n",
      "  Downloading open_flamingo-2.0.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting open_clip_torch\n",
      "  Downloading open_clip_torch-2.32.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting einops-exts\n",
      "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (2.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (1.24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.2) (9.3.0)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.30.0)\n",
      "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.0) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.30.0)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.0)\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers==4.30.0)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.30.0)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (3.25.0)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1) (15.0.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting ftfy (from open_clip_torch)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting timm (from open_clip_torch)\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0)\n",
      "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.0)\n",
      "  Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.2) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m232.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading open_flamingo-2.0.1-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.1.98-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m223.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading open_clip_torch-2.32.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m240.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
      "Downloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.8/514.8 kB\u001b[0m \u001b[31m168.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m202.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m164.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m194.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m250.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m257.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tokenizers, sentencepiece, tqdm, safetensors, regex, hf-xet, ftfy, fsspec, einops, huggingface-hub, einops-exts, transformers, timm, open_clip_torch, open-flamingo\n",
      "Successfully installed einops-0.8.1 einops-exts-0.0.4 fsspec-2025.5.1 ftfy-6.3.1 hf-xet-1.1.3 huggingface-hub-0.33.0 open-flamingo-2.0.1 open_clip_torch-2.32.0 regex-2024.11.6 safetensors-0.5.3 sentencepiece-0.1.98 timm-1.0.15 tokenizers-0.13.3 tqdm-4.67.1 transformers-4.30.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 필요한 라이브러리 설치\n",
    "!pip install torch==2.0.1 torchvision==0.15.2 transformers==4.30.0 einops sentencepiece open-flamingo open_clip_torch einops-exts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c3ee51-228e-4a90-bb4b-01c6dc11bcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-13 07:03:50--  https://huggingface.co/openflamingo/OpenFlamingo-9B-vitl-mpt7b/resolve/main/checkpoint.pt\n",
      "Resolving huggingface.co (huggingface.co)... 3.161.213.11, 3.161.213.58, 3.161.213.25, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.161.213.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.hf.co/repos/ab/66/ab66332de56d053921676567f6b428824815059fb070c094011b59e21d3d0852/ed5a634ff8c022cf437ec245838a00b0c05bef6963524c5d0dfabe75ce701514?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27checkpoint.pt%3B+filename%3D%22checkpoint.pt%22%3B&Expires=1749801830&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTgwMTgzMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hYi82Ni9hYjY2MzMyZGU1NmQwNTM5MjE2NzY1NjdmNmI0Mjg4MjQ4MTUwNTlmYjA3MGMwOTQwMTFiNTllMjFkM2QwODUyL2VkNWE2MzRmZjhjMDIyY2Y0MzdlYzI0NTgzOGEwMGIwYzA1YmVmNjk2MzUyNGM1ZDBkZmFiZTc1Y2U3MDE1MTQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=ETiL3gZVBua51-l1AA8hgGG%7EN-jzMGAxP-o1AFJmjyf7l8R94nVo8Ar6So2zV6U7NU4LeiZQvR%7ElkLy-kc3vbctI3xxH7VL1NG8fiByzP1vWg1RqBU5hbpK6NMur%7EmsDCsMy%7ETyEoxekaxdgQKhoZkqECVGT5T-X1kwGkTs3IZP-ukQk-KBAt4IXHjFnEBSejXVfPTApNPRw6ANsX34a25xP-ZE7cQ5a0XdnY5Dud%7EQPgoIGI1HItlOEpy6ZF6dfxE7Iid-Uk1jqQNslgxTojTjJGziYR0rH4kOZxcqa4OKqzQtFhAXSh8yuoiuUtvcTueNwQBlesgz2tKOfpRs1Ag__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
      "--2025-06-13 07:03:50--  https://cdn-lfs.hf.co/repos/ab/66/ab66332de56d053921676567f6b428824815059fb070c094011b59e21d3d0852/ed5a634ff8c022cf437ec245838a00b0c05bef6963524c5d0dfabe75ce701514?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27checkpoint.pt%3B+filename%3D%22checkpoint.pt%22%3B&Expires=1749801830&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTgwMTgzMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9hYi82Ni9hYjY2MzMyZGU1NmQwNTM5MjE2NzY1NjdmNmI0Mjg4MjQ4MTUwNTlmYjA3MGMwOTQwMTFiNTllMjFkM2QwODUyL2VkNWE2MzRmZjhjMDIyY2Y0MzdlYzI0NTgzOGEwMGIwYzA1YmVmNjk2MzUyNGM1ZDBkZmFiZTc1Y2U3MDE1MTQ%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=ETiL3gZVBua51-l1AA8hgGG%7EN-jzMGAxP-o1AFJmjyf7l8R94nVo8Ar6So2zV6U7NU4LeiZQvR%7ElkLy-kc3vbctI3xxH7VL1NG8fiByzP1vWg1RqBU5hbpK6NMur%7EmsDCsMy%7ETyEoxekaxdgQKhoZkqECVGT5T-X1kwGkTs3IZP-ukQk-KBAt4IXHjFnEBSejXVfPTApNPRw6ANsX34a25xP-ZE7cQ5a0XdnY5Dud%7EQPgoIGI1HItlOEpy6ZF6dfxE7Iid-Uk1jqQNslgxTojTjJGziYR0rH4kOZxcqa4OKqzQtFhAXSh8yuoiuUtvcTueNwQBlesgz2tKOfpRs1Ag__&Key-Pair-Id=K3RPWS32NSSJCE\n",
      "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.162.3.52, 3.162.3.51, 3.162.3.118, ...\n",
      "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.162.3.52|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5539171941 (5.2G) [binary/octet-stream]\n",
      "Saving to: ‘/workspace/OpenFlamingo/checkpoint.pt’\n",
      "\n",
      "/workspace/OpenFlam 100%[===================>]   5.16G   278MB/s    in 18s     \n",
      "\n",
      "2025-06-13 07:04:08 (288 MB/s) - ‘/workspace/OpenFlamingo/checkpoint.pt’ saved [5539171941/5539171941]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /workspace/OpenFlamingo\n",
    "\n",
    "!wget https://huggingface.co/openflamingo/OpenFlamingo-9B-vitl-mpt7b/resolve/main/checkpoint.pt \\\n",
    "  -O /workspace/OpenFlamingo/checkpoint.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645fc49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57370e2435e4cb489feae70bd77aaec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/open_clip/factory.py:388: UserWarning: These pretrained weights were trained with QuickGELU activation but the model config does not have that enabled. Consider using a model config with a \"-quickgelu\" suffix or enable with a flag.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7543a37ea8d4a26987bfa4b626eed3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/237 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56565349af204b8f8eb807c0594a70f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378c927b62b7469f8c513ece55272aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91347694d21b4823859f2d6b5c57fdbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e5f8ae93624fa48812ef418fd6c1c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_mpt.py:   0%|          | 0.00/9.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- configuration_mpt.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f165572f164a4f7d8a65d0f5692c7802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_mpt.py:   0%|          | 0.00/18.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca353df7896405d9fff900ccde81a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "meta_init_context.py:   0%|          | 0.00/3.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- meta_init_context.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458ffa2f90d847d7846064bf3c8ca5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "param_init_fns.py:   0%|          | 0.00/12.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b204f15439e64e4b82e6186f6cdf3112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "norm.py:   0%|          | 0.00/2.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- norm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- param_init_fns.py\n",
      "- norm.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd8bfe6f4bb448c8a44bb6e61d4698e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "flash_attn_triton.py:   0%|          | 0.00/28.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- flash_attn_triton.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af264d7fbeb4a0c83cd39c12849e2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapt_tokenizer.py:   0%|          | 0.00/1.75k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- adapt_tokenizer.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a6614da3b54ecd8cbeeda680213164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "attention.py:   0%|          | 0.00/17.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- attention.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d6e9515f9a4aea9815fc55a3eccf60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "blocks.py:   0%|          | 0.00/2.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- blocks.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe94a230984646429516d5e5ffebf4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hf_prefixlm_converter.py:   0%|          | 0.00/27.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- hf_prefixlm_converter.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/anas-awadalla/mpt-7b:\n",
      "- modeling_mpt.py\n",
      "- meta_init_context.py\n",
      "- param_init_fns.py\n",
      "- flash_attn_triton.py\n",
      "- adapt_tokenizer.py\n",
      "- attention.py\n",
      "- blocks.py\n",
      "- hf_prefixlm_converter.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7502a4a551054848abb29db53791753b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/16.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efde14d383a4e9c910df8806724b441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca782dd02004dc38f0bf8caf64536ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00003.bin:   0%|          | 0.00/9.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d447c325f6d47589a4c4eb6f717d58f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00003.bin:   0%|          | 0.00/9.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb35bac1915f46c79ea57f184c7d89b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00003.bin:   0%|          | 0.00/6.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66085fb00eba43919787815d3ead8315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74071e7d7adb4e0b80b336a2de2d2aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flamingo model initialized with 1384781840 trainable parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Flamingo(\n",
       "  (vision_encoder): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-23): 24 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (perceiver): PerceiverResampler(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x ModuleList(\n",
       "        (0): PerceiverAttention(\n",
       "          (norm_media): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm_latents): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=1024, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=1024, bias=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lang_encoder): MPTForCausalLM(\n",
       "    (transformer): MPTModel(\n",
       "      (wte): Embedding(50280, 4096)\n",
       "      (emb_drop): Dropout(p=0, inplace=False)\n",
       "      (blocks): ModuleList(\n",
       "        (0-2): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4-6): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8-10): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12-14): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16-18): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20-22): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (24-26): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (27): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (28-30): 3 x FlamingoLayer(\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (31): FlamingoLayer(\n",
       "          (gated_cross_attn_layer): GatedCrossAttentionBlock(\n",
       "            (attn): MaskedCrossAttention(\n",
       "              (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "            )\n",
       "            (ff): Sequential(\n",
       "              (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "              (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (decoder_layer): MPTBlock(\n",
       "            (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "              (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "            )\n",
       "            (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "            (ffn): MPTMLP(\n",
       "              (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "              (act): GELU(approximate='none')\n",
       "              (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "            )\n",
       "            (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "            (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_f): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (old_decoder_blocks): ModuleList(\n",
       "      (0-31): 32 x MPTBlock(\n",
       "        (norm_1): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (Wqkv): Linear(in_features=4096, out_features=12288, bias=False)\n",
       "          (out_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (norm_2): LPLayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (ffn): MPTMLP(\n",
       "          (up_proj): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (act): GELU(approximate='none')\n",
       "          (down_proj): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "        (resid_attn_dropout): Dropout(p=0, inplace=False)\n",
       "        (resid_ffn_dropout): Dropout(p=0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (gated_cross_attn_layers): ModuleList(\n",
       "      (0-2): 3 x None\n",
       "      (3): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (4-6): 3 x None\n",
       "      (7): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (8-10): 3 x None\n",
       "      (11): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (12-14): 3 x None\n",
       "      (15): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (16-18): 3 x None\n",
       "      (19): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (20-22): 3 x None\n",
       "      (23): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (24-26): 3 x None\n",
       "      (27): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "      (28-30): 3 x None\n",
       "      (31): GatedCrossAttentionBlock(\n",
       "        (attn): MaskedCrossAttention(\n",
       "          (norm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (to_q): Linear(in_features=4096, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (to_out): Linear(in_features=512, out_features=4096, bias=False)\n",
       "        )\n",
       "        (ff): Sequential(\n",
       "          (0): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "          (1): Linear(in_features=4096, out_features=16384, bias=False)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=16384, out_features=4096, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 필수 라이브러리 임포트\n",
    "import torch\n",
    "from open_flamingo import create_model_and_transforms\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# GPU 설정\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# 모델 로딩 (정확한 모델 조합 사용: ViT-L-14 + MPT-7B)\n",
    "model, image_processor, tokenizer = create_model_and_transforms(\n",
    "    clip_vision_encoder_path='ViT-L-14',\n",
    "    clip_vision_encoder_pretrained='openai',\n",
    "    lang_encoder_path='anas-awadalla/mpt-7b',\n",
    "    tokenizer_path='anas-awadalla/mpt-7b',\n",
    "    cross_attn_every_n_layers=4\n",
    ")\n",
    "    \n",
    "model.to(device)\n",
    "\n",
    "# OpenFlamingo 체크포인트 로딩 (사전 다운로드 필수)\n",
    "checkpoint_path = '/workspace/OpenFlamingo/checkpoint.pt'\n",
    "model.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f35f05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 처리 완료, shape: torch.Size([1, 1, 1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 이미지 불러오기\n",
    "image_url = 'https://images.unsplash.com/photo-1518791841217-8f162f1e1131'\n",
    "response = requests.get(image_url)\n",
    "image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "# 이미지 전처리 (모델 입력 형태로 변환)\n",
    "vision_x = image_processor(image).unsqueeze(0).unsqueeze(0).unsqueeze(2).to(device)\n",
    "print(\"이미지 처리 완료, shape:\", vision_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48383ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1259: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 OpenFlamingo가 생성한 이미지 설명: Describe this image in detail: A tabby cat sits on a couch\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 프롬프트 설정 ('<image>'는 필수 입력 토큰)\n",
    "prompt = \"<image>Describe this image in detail:\"\n",
    "tokenized_prompt = tokenizer(prompt, return_tensors='pt').to(device)\n",
    "\n",
    "# 설명 생성\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        vision_x=vision_x,\n",
    "        lang_x=tokenized_prompt['input_ids'],\n",
    "        attention_mask=tokenized_prompt['attention_mask'],\n",
    "        max_new_tokens=50,\n",
    "        num_beams=3,\n",
    "        do_sample=True, \n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "# 생성 결과 출력\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print('📝 OpenFlamingo가 생성한 이미지 설명:', generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35b059-8308-47ad-800a-88a8a675bb73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
